#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æµ‹è¯•è½¨è¿¹å®šä½ç³»ç»Ÿ
"""

import numpy as np
import torch
from trajectory_localization_system import TrajectoryLocalizationSystem
from utils.scan_context import ScanContext
import time
import matplotlib.pyplot as plt

# å°è¯•å¯¼å…¥rosbagç›¸å…³åº“
try:
    import rosbag
    import sensor_msgs.point_cloud2 as pc2
    ROSBAG_AVAILABLE = True
except ImportError:
    ROSBAG_AVAILABLE = False

class TrajectoryLocalizationTester:
    """è½¨è¿¹å®šä½æµ‹è¯•å™¨"""
    
    def __init__(self, model_path, database_path):
        self.localizer = TrajectoryLocalizationSystem(num_locations=20)
        self.sc_generator = ScanContext()
        
        print(f"ğŸ¯ è½¨è¿¹å®šä½æµ‹è¯•å™¨")
        print(f"ç›®æ ‡: å®æ—¶è¯†åˆ«æœºå™¨äººåœ¨è½¨è¿¹ä¸­çš„ä½ç½®")
        
        # åŠ è½½ä½ç½®æ•°æ®åº“
        if not self.localizer.load_location_database(database_path):
            print("âŒ ä½ç½®æ•°æ®åº“åŠ è½½å¤±è´¥")
            return
        
        # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
        if not self.localizer.load_trained_model(model_path):
            print("âŒ å®šä½æ¨¡å‹åŠ è½½å¤±è´¥")
            return
        
        print("âœ… è½¨è¿¹å®šä½ç³»ç»Ÿå‡†å¤‡å°±ç»ª")
        
        # å®šä½å†å²
        self.localization_history = []
        self.confidence_history = []
        self.timestamp_history = []
    
    def pointcloud2_to_numpy(self, cloud_msg):
        """å°†PointCloud2æ¶ˆæ¯è½¬æ¢ä¸ºnumpyæ•°ç»„"""
        if not ROSBAG_AVAILABLE:
            return None
            
        try:
            points_list = []
            for point in pc2.read_points(cloud_msg, field_names=("x", "y", "z"), skip_nans=True):
                points_list.append([point[0], point[1], point[2]])
            
            if len(points_list) == 0:
                return None
                
            points = np.array(points_list, dtype=np.float32)
            valid_mask = np.isfinite(points).all(axis=1)
            points = points[valid_mask]
            
            distances = np.linalg.norm(points[:, :2], axis=1)
            distance_mask = distances < 50.0
            points = points[distance_mask]
            
            if len(points) < 100:
                return None
                
            return points
            
        except Exception as e:
            print(f"ç‚¹äº‘è½¬æ¢å¤±è´¥: {e}")
            return None
    
    def test_rosbag_localization(self, bag_path, topic_name=None):
        """æµ‹è¯•rosbagçš„è½¨è¿¹å®šä½"""
        
        if not ROSBAG_AVAILABLE:
            print("âŒ rosbagåº“ä¸å¯ç”¨")
            return None
            
        try:
            bag = rosbag.Bag(bag_path, 'r')
        except Exception as e:
            print(f"æ— æ³•æ‰“å¼€rosbagæ–‡ä»¶: {e}")
            return None
        
        # è·å–è¯é¢˜ä¿¡æ¯
        topics_info = bag.get_type_and_topic_info()[1]
        print(f"\nrosbagè¯é¢˜ä¿¡æ¯:")
        
        pointcloud_topics = []
        for topic, info in topics_info.items():
            print(f"  {topic}: {info.msg_type} ({info.message_count} æ¶ˆæ¯)")
            if 'PointCloud2' in info.msg_type:
                pointcloud_topics.append(topic)
        
        if not pointcloud_topics:
            print("âŒ æœªæ‰¾åˆ°PointCloud2è¯é¢˜")
            bag.close()
            return None
        
        if topic_name is None:
            topic_name = pointcloud_topics[0]
        
        print(f"\nğŸ¯ å¼€å§‹è½¨è¿¹å®šä½æµ‹è¯•")
        print(f"ä½¿ç”¨è¯é¢˜: {topic_name}")
        print(f"ç›®æ ‡: è¯†åˆ«æœºå™¨äººåœ¨è½¨è¿¹ä¸­çš„ä½ç½® (0-{self.localizer.num_locations-1})")
        print("-" * 60)
        
        # å¤„ç†æ¶ˆæ¯
        total_messages = 0
        valid_localizations = 0
        start_time = time.time()
        
        for topic, msg, t in bag.read_messages(topics=[topic_name]):
            total_messages += 1
            timestamp = t.to_sec()
            
            # è½¬æ¢ç‚¹äº‘
            points = self.pointcloud2_to_numpy(msg)
            if points is None:
                continue
            
            # ç”ŸæˆScanContext
            sc_feature = self.sc_generator.generate_scan_context(points)
            if sc_feature is None:
                continue
            
            # å®šä½
            predicted_location, confidence = self.localizer.localize_position(sc_feature)
            
            if predicted_location is not None:
                valid_localizations += 1
                
                # ä¿å­˜ç»“æœ
                self.localization_history.append(predicted_location)
                self.confidence_history.append(confidence)
                self.timestamp_history.append(timestamp)
                
                # è®¡ç®—æœŸæœ›ä½ç½®ï¼ˆåŸºäºè¿›åº¦ï¼‰
                expected_location = int((total_messages - 1) / (1769 / self.localizer.num_locations))
                expected_location = min(expected_location, self.localizer.num_locations - 1)
                
                # è®¡ç®—å®šä½è¯¯å·®
                location_error = abs(predicted_location - expected_location)
                
                # å®æ—¶è¾“å‡º
                status = "âœ…" if location_error <= 2 else "âŒ"
                print(f"æ¶ˆæ¯ {total_messages:4d} | é¢„æµ‹ä½ç½®: {predicted_location:2d} | "
                      f"æœŸæœ›ä½ç½®: {expected_location:2d} | è¯¯å·®: {location_error:2d} | "
                      f"ç½®ä¿¡åº¦: {confidence:.4f} | ç‚¹æ•°: {len(points):5d} {status}")
                
                # æ¯50ä¸ªå®šä½æ˜¾ç¤ºç»Ÿè®¡
                if valid_localizations % 50 == 0:
                    self.show_localization_stats()
            
            # å¤„ç†å®Œæ•´æ•°æ®é›†
            if total_messages >= 1769:
                print(f"\nå·²å¤„ç†å®Œæ•´æ•°æ®é›† ({total_messages} ä¸ªæ¶ˆæ¯)")
                break
        
        bag.close()
        
        elapsed_time = time.time() - start_time
        print(f"\n" + "="*60)
        print("è½¨è¿¹å®šä½æµ‹è¯•å®Œæˆ")
        print("="*60)
        print(f"æ€»æ¶ˆæ¯æ•°: {total_messages}")
        print(f"æœ‰æ•ˆå®šä½æ•°: {valid_localizations}")
        print(f"æˆåŠŸç‡: {valid_localizations/total_messages*100:.1f}%")
        print(f"å¤„ç†æ—¶é—´: {elapsed_time:.1f}ç§’")
        print(f"å®šä½é¢‘ç‡: {valid_localizations/elapsed_time:.2f} Hz")
        
        return self.analyze_localization_results()
    
    def show_localization_stats(self):
        """æ˜¾ç¤ºå®šä½ç»Ÿè®¡"""
        if len(self.localization_history) == 0:
            return
        
        locations = np.array(self.localization_history)
        confidences = np.array(self.confidence_history)
        
        print(f"\n--- è½¨è¿¹å®šä½ç»Ÿè®¡ (æœ€è¿‘{len(locations)}ä¸ªå®šä½) ---")
        print(f"ä½ç½®èŒƒå›´: {np.min(locations)} - {np.max(locations)}")
        print(f"å¹³å‡ç½®ä¿¡åº¦: {np.mean(confidences):.4f}")
        print(f"æœ€é«˜ç½®ä¿¡åº¦: {np.max(confidences):.4f}")
        
        # æœ€è¿‘å®šä½çš„åˆ†å¸ƒ
        recent_locations = locations[-20:] if len(locations) > 20 else locations
        unique, counts = np.unique(recent_locations, return_counts=True)
        print("æœ€è¿‘20ä¸ªå®šä½çš„ä½ç½®åˆ†å¸ƒ:")
        for loc, count in zip(unique, counts):
            print(f"  ä½ç½® {loc}: {count} æ¬¡")
        print("-" * 50)
    
    def analyze_localization_results(self):
        """åˆ†æå®šä½ç»“æœ"""
        if len(self.localization_history) == 0:
            return None
        
        locations = np.array(self.localization_history)
        confidences = np.array(self.confidence_history)
        timestamps = np.array(self.timestamp_history)
        
        print(f"\nğŸ“Š è½¨è¿¹å®šä½ç»“æœåˆ†æ")
        print(f"{'='*50}")
        
        # åŸºæœ¬ç»Ÿè®¡
        print(f"å®šä½ä½ç½®æ•°é‡: {len(np.unique(locations))}")
        print(f"ä½ç½®èŒƒå›´: {np.min(locations)} - {np.max(locations)}")
        print(f"å¹³å‡ç½®ä¿¡åº¦: {np.mean(confidences):.4f}")
        print(f"ç½®ä¿¡åº¦æ ‡å‡†å·®: {np.std(confidences):.4f}")
        
        # ä½ç½®åˆ†å¸ƒ
        print(f"\nä½ç½®åˆ†å¸ƒ:")
        unique, counts = np.unique(locations, return_counts=True)
        for loc, count in zip(unique, counts):
            percentage = count / len(locations) * 100
            avg_conf = np.mean(confidences[locations == loc])
            print(f"  ä½ç½® {loc:2d}: {count:3d} æ¬¡ ({percentage:5.1f}%) | å¹³å‡ç½®ä¿¡åº¦: {avg_conf:.4f}")
        
        # æ—¶åºåˆ†æ
        print(f"\næ—¶åºåˆ†æ:")
        if len(timestamps) > 1:
            time_duration = timestamps[-1] - timestamps[0]
            print(f"æ•°æ®æ—¶é•¿: {time_duration:.1f} ç§’")
            print(f"å®šä½é¢‘ç‡: {len(locations)/time_duration:.2f} Hz")
        
        # ä½ç½®å˜åŒ–åˆ†æ
        print(f"\nä½ç½®å˜åŒ–åˆ†æ:")
        location_changes = []
        for i in range(1, len(locations)):
            if locations[i] != locations[i-1]:
                location_changes.append((i, locations[i-1], locations[i]))
        
        print(f"ä½ç½®å˜åŒ–æ¬¡æ•°: {len(location_changes)}")
        if len(location_changes) > 0:
            print("ä¸»è¦ä½ç½®å˜åŒ–:")
            for i, (pos, from_loc, to_loc) in enumerate(location_changes[:10]):
                print(f"  ä½ç½® {pos}: {from_loc} â†’ {to_loc}")
        
        # è®¡ç®—å®šä½å‡†ç¡®æ€§
        expected_locations = np.linspace(0, self.localizer.num_locations-1, len(locations)).astype(int)
        location_errors = np.abs(locations - expected_locations)
        
        accuracy_1 = np.mean(location_errors <= 1) * 100  # è¯¯å·®â‰¤1çš„å‡†ç¡®ç‡
        accuracy_2 = np.mean(location_errors <= 2) * 100  # è¯¯å·®â‰¤2çš„å‡†ç¡®ç‡
        accuracy_3 = np.mean(location_errors <= 3) * 100  # è¯¯å·®â‰¤3çš„å‡†ç¡®ç‡
        
        print(f"\nå®šä½å‡†ç¡®æ€§åˆ†æ:")
        print(f"è¯¯å·®â‰¤1ä½ç½®çš„å‡†ç¡®ç‡: {accuracy_1:.1f}%")
        print(f"è¯¯å·®â‰¤2ä½ç½®çš„å‡†ç¡®ç‡: {accuracy_2:.1f}%")
        print(f"è¯¯å·®â‰¤3ä½ç½®çš„å‡†ç¡®ç‡: {accuracy_3:.1f}%")
        print(f"å¹³å‡ä½ç½®è¯¯å·®: {np.mean(location_errors):.2f}")
        
        # å¯è§†åŒ–ç»“æœ
        self.visualize_localization_results(locations, confidences, expected_locations)
        
        return {
            'locations': locations.tolist(),
            'confidences': confidences.tolist(),
            'timestamps': timestamps.tolist(),
            'accuracy_1': accuracy_1,
            'accuracy_2': accuracy_2,
            'accuracy_3': accuracy_3,
            'location_changes': len(location_changes),
            'mean_error': np.mean(location_errors)
        }
    
    def visualize_localization_results(self, locations, confidences, expected_locations):
        """å¯è§†åŒ–å®šä½ç»“æœ"""
        fig, axes = plt.subplots(3, 1, figsize=(15, 10))
        
        # 1. ä½ç½®é¢„æµ‹vsæœŸæœ›
        axes[0].plot(expected_locations, 'b-', alpha=0.7, label='æœŸæœ›ä½ç½®')
        axes[0].plot(locations, 'r-', alpha=0.7, label='é¢„æµ‹ä½ç½®')
        axes[0].set_ylabel('ä½ç½®ID')
        axes[0].set_title('è½¨è¿¹å®šä½ç»“æœï¼šé¢„æµ‹ä½ç½® vs æœŸæœ›ä½ç½®')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)
        
        # 2. å®šä½ç½®ä¿¡åº¦
        axes[1].plot(confidences, 'g-', alpha=0.7, label='å®šä½ç½®ä¿¡åº¦')
        axes[1].set_ylabel('ç½®ä¿¡åº¦')
        axes[1].set_title('å®šä½ç½®ä¿¡åº¦å˜åŒ–')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)
        
        # 3. ä½ç½®è¯¯å·®
        location_errors = np.abs(locations - expected_locations)
        axes[2].plot(location_errors, 'orange', alpha=0.7, label='ä½ç½®è¯¯å·®')
        axes[2].axhline(y=1, color='red', linestyle='--', alpha=0.5, label='è¯¯å·®=1')
        axes[2].axhline(y=2, color='red', linestyle='--', alpha=0.5, label='è¯¯å·®=2')
        axes[2].set_ylabel('ä½ç½®è¯¯å·®')
        axes[2].set_xlabel('å¸§ç´¢å¼•')
        axes[2].set_title('å®šä½è¯¯å·®åˆ†æ')
        axes[2].legend()
        axes[2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('trajectory_localization_results.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"ğŸ“Š å®šä½ç»“æœå›¾è¡¨å·²ä¿å­˜ä¸º trajectory_localization_results.png")

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python test_trajectory_localization.py <bag_path> [topic_name]")
        return
    
    bag_path = sys.argv[1]
    topic_name = sys.argv[2] if len(sys.argv) > 2 else None
    
    print("="*60)
    print("ğŸ¯ è½¨è¿¹å®šä½ç³»ç»Ÿæµ‹è¯•")
    print("="*60)
    print(f"ç›®æ ‡: è¯†åˆ«æœºå™¨äººåœ¨è½¨è¿¹ä¸­çš„å…·ä½“ä½ç½®")
    print(f"rosbag: {bag_path}")
    
    # æ¨¡å‹å’Œæ•°æ®åº“è·¯å¾„
    model_path = "models/saved/trajectory_localizer_simple2dcnn_acc*.pth"
    database_path = "location_database.pkl"
    
    # æŸ¥æ‰¾æœ€æ–°çš„æ¨¡å‹æ–‡ä»¶
    import glob
    model_files = glob.glob(model_path)
    if not model_files:
        print(f"âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶")
        print(f"è¯·å…ˆè¿è¡Œ trajectory_localization_system.py è®­ç»ƒæ¨¡å‹")
        return
    
    model_path = sorted(model_files)[-1]  # ä½¿ç”¨æœ€æ–°çš„æ¨¡å‹
    print(f"ä½¿ç”¨æ¨¡å‹: {model_path}")
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = TrajectoryLocalizationTester(model_path, database_path)
    
    # æµ‹è¯•å®šä½
    results = tester.test_rosbag_localization(bag_path, topic_name)
    
    if results:
        print(f"\nâœ… è½¨è¿¹å®šä½æµ‹è¯•å®Œæˆï¼")
        print(f"è¯¯å·®â‰¤1ä½ç½®å‡†ç¡®ç‡: {results['accuracy_1']:.1f}%")
        print(f"è¯¯å·®â‰¤2ä½ç½®å‡†ç¡®ç‡: {results['accuracy_2']:.1f}%")
        print(f"å¹³å‡ä½ç½®è¯¯å·®: {results['mean_error']:.2f}")
        print(f"ä½ç½®å˜åŒ–æ¬¡æ•°: {results['location_changes']}")
        
        # ä¿å­˜ç»“æœ
        import pickle
        result_path = 'trajectory_localization_test_results.pkl'
        with open(result_path, 'wb') as f:
            pickle.dump(results, f)
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {result_path}")
    else:
        print("âŒ è½¨è¿¹å®šä½æµ‹è¯•å¤±è´¥")

if __name__ == '__main__':
    main()
