#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç”Ÿæˆè®ºæ–‡æ‰€éœ€çš„å…³é”®å®éªŒç»“æœ
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import pickle
from pathlib import Path
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import seaborn as sns
from models.temporal_models import *
import warnings
warnings.filterwarnings('ignore')

def quick_train_and_test(model, train_data, train_labels, test_data, test_labels, epochs=30):
    """å¿«é€Ÿè®­ç»ƒå’Œæµ‹è¯•æ¨¡å‹"""
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    
    # å‡†å¤‡æ•°æ®
    train_tensor = torch.FloatTensor(train_data).to(device)
    train_labels_tensor = torch.LongTensor(train_labels).to(device)
    test_tensor = torch.FloatTensor(test_data).to(device)
    
    train_dataset = TensorDataset(train_tensor, train_labels_tensor)
    train_loader = DataLoader(train_dataset, batch_size=min(32, len(train_data)), shuffle=True)
    
    # è®­ç»ƒ
    model.train()
    for epoch in range(epochs):
        for batch_data, batch_labels in train_loader:
            optimizer.zero_grad()
            outputs = model(batch_data)
            loss = criterion(outputs, batch_labels)
            loss.backward()
            optimizer.step()
    
    # æµ‹è¯•
    model.eval()
    with torch.no_grad():
        test_outputs = model(test_tensor)
        _, predicted = torch.max(test_outputs.data, 1)
        accuracy = accuracy_score(test_labels, predicted.cpu().numpy())
    
    return accuracy, predicted.cpu().numpy()

def experiment_1_temporal_split():
    """å®éªŒ1: æ—¶é—´åˆ†ç¦»æµ‹è¯•"""
    
    print("\n" + "="*60)
    print("å®éªŒ1: æ—¶é—´åˆ†ç¦»æµ‹è¯• - é¿å…æ—¶åºæ•°æ®æ³„éœ²")
    print("="*60)
    
    # åŠ è½½æ•°æ®
    with open('data/processed/temporal_split.pkl', 'rb') as f:
        data = pickle.load(f)
    
    train_sequences = data['train_sequences']
    train_labels = data['train_labels']
    test_sequences = data['test_sequences']
    test_labels = data['test_labels']
    
    print(f"è®­ç»ƒé›†: {len(train_sequences)} æ ·æœ¬, ç±»åˆ«: {sorted(set(train_labels))}")
    print(f"æµ‹è¯•é›†: {len(test_sequences)} æ ·æœ¬, ç±»åˆ«: {sorted(set(test_labels))}")
    
    # é‡æ–°æ˜ å°„æ ‡ç­¾åˆ°è¿ç»­çš„0-N
    unique_test_labels = sorted(set(test_labels))
    label_map = {old_label: new_label for new_label, old_label in enumerate(unique_test_labels)}
    
    mapped_train_labels = [label_map.get(label, -1) for label in train_labels]
    mapped_test_labels = [label_map[label] for label in test_labels]
    
    # åªä¿ç•™è®­ç»ƒé›†ä¸­å­˜åœ¨çš„ç±»åˆ«
    valid_train_mask = np.array(mapped_train_labels) >= 0
    train_sequences = train_sequences[valid_train_mask]
    mapped_train_labels = np.array(mapped_train_labels)[valid_train_mask]
    
    num_classes = len(unique_test_labels)
    print(f"æœ‰æ•ˆç±»åˆ«æ•°: {num_classes}")
    
    # æµ‹è¯•ä¸åŒæ¨¡å‹
    models = [
        ("2D CNN", Temporal2DCNN((5, 20, 60), num_classes)),
        ("ç®€å•CNN", SimpleCNN((20, 60), num_classes))
    ]
    
    results = {}
    
    for model_name, model in models:
        print(f"\næµ‹è¯• {model_name}:")
        try:
            accuracy, predictions = quick_train_and_test(
                model, train_sequences, mapped_train_labels, 
                test_sequences, mapped_test_labels, epochs=20
            )
            results[model_name] = accuracy
            print(f"  å‡†ç¡®ç‡: {accuracy:.4f}")
        except Exception as e:
            print(f"  âŒ å¤±è´¥: {e}")
            results[model_name] = 0.0
    
    return results

def experiment_2_few_shot():
    """å®éªŒ2: å°‘æ ·æœ¬å­¦ä¹ """
    
    print("\n" + "="*60)
    print("å®éªŒ2: å°‘æ ·æœ¬å­¦ä¹ ")
    print("="*60)
    
    # åŠ è½½æ•°æ®
    with open('data/processed/few_shot_splits.pkl', 'rb') as f:
        few_shot_data = pickle.load(f)
    
    results = {}
    
    for k_shot in ['1_shot', '3_shot', '5_shot']:
        print(f"\n{k_shot} å­¦ä¹ :")
        
        train_sequences = few_shot_data[k_shot]['train_sequences']
        train_labels = few_shot_data[k_shot]['train_labels']
        test_sequences = few_shot_data[k_shot]['test_sequences']
        test_labels = few_shot_data[k_shot]['test_labels']
        
        print(f"  è®­ç»ƒé›†: {len(train_sequences)} æ ·æœ¬")
        print(f"  æµ‹è¯•é›†: {len(test_sequences)} æ ·æœ¬")
        
        # ä½¿ç”¨ç®€å•æ¨¡å‹
        model = SimpleCNN((20, 60), 20)
        
        try:
            accuracy, _ = quick_train_and_test(
                model, train_sequences, train_labels,
                test_sequences, test_labels, epochs=50
            )
            results[k_shot] = accuracy
            print(f"  å‡†ç¡®ç‡: {accuracy:.4f}")
        except Exception as e:
            print(f"  âŒ å¤±è´¥: {e}")
            results[k_shot] = 0.0
    
    return results

def experiment_3_noise_robustness():
    """å®éªŒ3: å™ªå£°é²æ£’æ€§"""
    
    print("\n" + "="*60)
    print("å®éªŒ3: å™ªå£°é²æ£’æ€§æµ‹è¯•")
    print("="*60)
    
    # åŠ è½½åŸå§‹æ•°æ®ç”¨äºè®­ç»ƒ
    data_file = Path("data/processed/temporal_sequences_len5.pkl")
    with open(data_file, 'rb') as f:
        original_data = pickle.load(f)
    
    sequences = original_data['sequences']
    labels = original_data['labels']
    
    # æ•°æ®åˆ’åˆ†
    n_train = int(0.8 * len(sequences))
    train_sequences = sequences[:n_train]
    train_labels = labels[:n_train]
    
    # è®­ç»ƒä¸€ä¸ªåŸºç¡€æ¨¡å‹
    print("è®­ç»ƒåŸºç¡€æ¨¡å‹...")
    base_model = SimpleCNN((20, 60), 20)
    base_accuracy, _ = quick_train_and_test(
        base_model, train_sequences, train_labels,
        sequences[n_train:], labels[n_train:], epochs=30
    )
    print(f"åŸºç¡€æ¨¡å‹å‡†ç¡®ç‡: {base_accuracy:.4f}")
    
    # åŠ è½½å™ªå£°æ•°æ®
    with open('data/processed/noise_robustness.pkl', 'rb') as f:
        noisy_data = pickle.load(f)
    
    results = {'clean': base_accuracy}
    noise_levels = [0.01, 0.05, 0.1, 0.2, 0.3]
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    base_model = base_model.to(device)
    base_model.eval()
    
    for noise_level in noise_levels:
        print(f"\nå™ªå£°æ°´å¹³: {noise_level}")
        
        noisy_sequences = noisy_data[f'noise_{noise_level}']['sequences']
        test_noisy = noisy_sequences[n_train:]
        test_labels = labels[n_train:]
        
        # æµ‹è¯•å™ªå£°æ•°æ®
        test_tensor = torch.FloatTensor(test_noisy).to(device)
        
        with torch.no_grad():
            outputs = base_model(test_tensor)
            _, predicted = torch.max(outputs.data, 1)
            accuracy = accuracy_score(test_labels, predicted.cpu().numpy())
        
        results[f'noise_{noise_level}'] = accuracy
        print(f"  å‡†ç¡®ç‡: {accuracy:.4f}")
    
    return results

def experiment_4_ablation():
    """å®éªŒ4: æ¶ˆèç ”ç©¶"""
    
    print("\n" + "="*60)
    print("å®éªŒ4: æ¶ˆèç ”ç©¶")
    print("="*60)
    
    # åŠ è½½æ¶ˆèæ•°æ®
    with open('data/processed/ablation_study.pkl', 'rb') as f:
        ablation_data = pickle.load(f)
    
    results = {}
    
    configs = [
        ('single_frame', 'å•å¸§ç‰¹å¾'),
        ('seq_len_2', 'æ—¶åºé•¿åº¦2'),
        ('seq_len_3', 'æ—¶åºé•¿åº¦3'),
        ('seq_len_4', 'æ—¶åºé•¿åº¦4'),
        ('seq_len_5', 'æ—¶åºé•¿åº¦5 (å®Œæ•´)'),
    ]
    
    for config_name, config_desc in configs:
        print(f"\n{config_desc}:")
        
        sequences = ablation_data[config_name]['sequences']
        labels = ablation_data[config_name]['labels']
        
        print(f"  æ•°æ®å½¢çŠ¶: {sequences.shape}")
        
        # æ•°æ®åˆ’åˆ†
        n_train = int(0.8 * len(sequences))
        train_sequences = sequences[:n_train]
        train_labels = labels[:n_train]
        test_sequences = sequences[n_train:]
        test_labels = labels[n_train:]
        
        # é€‰æ‹©åˆé€‚çš„æ¨¡å‹
        if len(sequences.shape) == 3:  # å•å¸§
            model = SimpleCNN((sequences.shape[1], sequences.shape[2]), 20)
        else:  # å¤šå¸§
            model = SimpleCNN((sequences.shape[2], sequences.shape[3]), 20)
        
        try:
            accuracy, _ = quick_train_and_test(
                model, train_sequences, train_labels,
                test_sequences, test_labels, epochs=30
            )
            results[config_name] = accuracy
            print(f"  å‡†ç¡®ç‡: {accuracy:.4f}")
        except Exception as e:
            print(f"  âŒ å¤±è´¥: {e}")
            results[config_name] = 0.0
    
    return results

def generate_paper_plots(all_results):
    """ç”Ÿæˆè®ºæ–‡å›¾è¡¨"""
    
    print("\n" + "="*60)
    print("ç”Ÿæˆè®ºæ–‡å›¾è¡¨")
    print("="*60)
    
    # ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
    Path('results/figures').mkdir(parents=True, exist_ok=True)
    
    # 1. å°‘æ ·æœ¬å­¦ä¹ ç»“æœ
    if 'few_shot' in all_results:
        plt.figure(figsize=(10, 6))
        few_shot_results = all_results['few_shot']
        
        shots = [1, 3, 5]
        accuracies = [few_shot_results.get(f'{k}_shot', 0) for k in shots]
        
        plt.plot(shots, accuracies, 'bo-', linewidth=2, markersize=8)
        plt.xlabel('Number of Training Samples per Class')
        plt.ylabel('Accuracy')
        plt.title('Few-Shot Learning Performance')
        plt.grid(True, alpha=0.3)
        plt.ylim(0, 1)
        
        for i, (shot, acc) in enumerate(zip(shots, accuracies)):
            plt.annotate(f'{acc:.3f}', (shot, acc), textcoords="offset points", 
                        xytext=(0,10), ha='center')
        
        plt.tight_layout()
        plt.savefig('results/figures/few_shot_learning.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("âœ… å°‘æ ·æœ¬å­¦ä¹ å›¾è¡¨å·²ä¿å­˜")
    
    # 2. å™ªå£°é²æ£’æ€§ç»“æœ
    if 'noise_robustness' in all_results:
        plt.figure(figsize=(10, 6))
        noise_results = all_results['noise_robustness']
        
        noise_levels = [0, 0.01, 0.05, 0.1, 0.2, 0.3]
        accuracies = [noise_results.get('clean' if level == 0 else f'noise_{level}', 0) 
                     for level in noise_levels]
        
        plt.plot(noise_levels, accuracies, 'ro-', linewidth=2, markersize=8)
        plt.xlabel('Noise Level (Ïƒ)')
        plt.ylabel('Accuracy')
        plt.title('Noise Robustness Analysis')
        plt.grid(True, alpha=0.3)
        plt.ylim(0, 1)
        
        plt.tight_layout()
        plt.savefig('results/figures/noise_robustness.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("âœ… å™ªå£°é²æ£’æ€§å›¾è¡¨å·²ä¿å­˜")
    
    # 3. æ¶ˆèç ”ç©¶ç»“æœ
    if 'ablation' in all_results:
        plt.figure(figsize=(12, 6))
        ablation_results = all_results['ablation']
        
        configs = ['single_frame', 'seq_len_2', 'seq_len_3', 'seq_len_4', 'seq_len_5']
        labels = ['Single Frame', 'Seq Len 2', 'Seq Len 3', 'Seq Len 4', 'Seq Len 5']
        accuracies = [ablation_results.get(config, 0) for config in configs]
        
        bars = plt.bar(labels, accuracies, color=['skyblue', 'lightgreen', 'lightcoral', 'gold', 'plum'])
        plt.xlabel('Configuration')
        plt.ylabel('Accuracy')
        plt.title('Ablation Study: Temporal Sequence Length')
        plt.ylim(0, 1)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, acc in zip(bars, accuracies):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{acc:.3f}', ha='center', va='bottom')
        
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig('results/figures/ablation_study.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("âœ… æ¶ˆèç ”ç©¶å›¾è¡¨å·²ä¿å­˜")

def main():
    """ä¸»å‡½æ•°"""
    
    print("å¼€å§‹è®ºæ–‡å®éªŒ...")
    
    # è¿è¡Œæ‰€æœ‰å®éªŒ
    results = {}
    
    try:
        results['temporal_split'] = experiment_1_temporal_split()
    except Exception as e:
        print(f"æ—¶é—´åˆ†ç¦»å®éªŒå¤±è´¥: {e}")
        results['temporal_split'] = {}
    
    try:
        results['few_shot'] = experiment_2_few_shot()
    except Exception as e:
        print(f"å°‘æ ·æœ¬å­¦ä¹ å®éªŒå¤±è´¥: {e}")
        results['few_shot'] = {}
    
    try:
        results['noise_robustness'] = experiment_3_noise_robustness()
    except Exception as e:
        print(f"å™ªå£°é²æ£’æ€§å®éªŒå¤±è´¥: {e}")
        results['noise_robustness'] = {}
    
    try:
        results['ablation'] = experiment_4_ablation()
    except Exception as e:
        print(f"æ¶ˆèç ”ç©¶å®éªŒå¤±è´¥: {e}")
        results['ablation'] = {}
    
    # ä¿å­˜ç»“æœ
    with open('results/paper_experiments_results.pkl', 'wb') as f:
        pickle.dump(results, f)
    
    # ç”Ÿæˆå›¾è¡¨
    generate_paper_plots(results)
    
    # æ‰“å°æ€»ç»“
    print("\n" + "="*60)
    print("å®éªŒç»“æœæ€»ç»“")
    print("="*60)
    
    for exp_name, exp_results in results.items():
        print(f"\n{exp_name}:")
        for key, value in exp_results.items():
            print(f"  {key}: {value:.4f}")
    
    print(f"\nâœ… æ‰€æœ‰å®éªŒå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ° results/paper_experiments_results.pkl")
    print(f"ğŸ“Š å›¾è¡¨å·²ä¿å­˜åˆ° results/figures/ ç›®å½•")

if __name__ == '__main__':
    main()
