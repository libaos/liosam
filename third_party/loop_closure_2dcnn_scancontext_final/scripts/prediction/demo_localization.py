#!/usr/bin/env python3
"""
ä½ç½®å®šä½æ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¦‚ä½•ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œä½ç½®å®šä½
"""
import argparse
from pathlib import Path
import json
import time

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

from localize_position import PositionLocalizer

def demo_single_localization():
    """å•æ¬¡å®šä½æ¼”ç¤º"""
    print("ğŸ¯ å•æ¬¡ä½ç½®å®šä½æ¼”ç¤º")
    print("=" * 50)
    
    # ä½¿ç”¨æœ€æ–°çš„æ¨¡å‹
    model_path = "outputs/models/best_sc_ring_cnn_20250802_165529.pth"
    map_database_path = "data/raw/ply_files"
    
    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
    if not Path(model_path).exists():
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–æŒ‡å®šæ­£ç¡®çš„æ¨¡å‹è·¯å¾„")
        return
    
    if not Path(map_database_path).exists():
        print(f"âŒ åœ°å›¾æ•°æ®åº“ä¸å­˜åœ¨: {map_database_path}")
        return
    
    try:
        # åˆå§‹åŒ–å®šä½å™¨
        print("ğŸ”„ åˆå§‹åŒ–ä½ç½®å®šä½å™¨...")
        localizer = PositionLocalizer(model_path, map_database_path, device='cpu')
        
        # è·å–åœ°å›¾ä¸­çš„ä¸€ä¸ªæ–‡ä»¶ä½œä¸ºæŸ¥è¯¢ç¤ºä¾‹
        ply_files = list(Path(map_database_path).glob("*.ply"))
        if len(ply_files) == 0:
            print("âŒ åœ°å›¾æ•°æ®åº“ä¸­æ²¡æœ‰PLYæ–‡ä»¶")
            return
        
        # é€‰æ‹©ä¸­é—´çš„ä¸€ä¸ªæ–‡ä»¶ä½œä¸ºæŸ¥è¯¢
        query_file = ply_files[len(ply_files) // 2]
        print(f"ğŸ” ä½¿ç”¨æŸ¥è¯¢æ–‡ä»¶: {query_file.name}")
        
        # æ‰§è¡Œå®šä½
        print("ğŸš€ æ‰§è¡Œä½ç½®å®šä½...")
        start_time = time.time()
        result = localizer.localize_from_ply(str(query_file), top_k=5)
        end_time = time.time()
        
        # æ˜¾ç¤ºç»“æœ
        print("\nâœ… å®šä½å®Œæˆï¼")
        print(f"â±ï¸  å¤„ç†æ—¶é—´: {end_time - start_time:.3f}ç§’")
        print(f"ğŸ¯ æœ€ä½³åŒ¹é…ä½ç½®: {result['best_position_index']}")
        print(f"ğŸ“„ å¯¹åº”æ–‡ä»¶: {result['best_map_file']}")
        print(f"ğŸ”— ç›¸ä¼¼åº¦: {result['best_similarity']:.4f}")
        print(f"ğŸšï¸  ç½®ä¿¡åº¦: {result['confidence']}")
        
        print(f"\nğŸ“‹ å‰5ä¸ªå€™é€‰ä½ç½®:")
        for i, candidate in enumerate(result['top_k_candidates']):
            print(f"  {i+1}. ä½ç½® {candidate['position_index']:3d}: "
                  f"ç›¸ä¼¼åº¦={candidate['similarity']:.4f}, "
                  f"æ–‡ä»¶={candidate['map_file']}")
        
        # åˆ†æç»“æœ
        print(f"\nğŸ“Š ç»“æœåˆ†æ:")
        if result['best_similarity'] > 0.9:
            print("ğŸŸ¢ å®šä½ç²¾åº¦: æé«˜ - å‡ ä¹å®Œç¾åŒ¹é…")
        elif result['best_similarity'] > 0.8:
            print("ğŸŸ¡ å®šä½ç²¾åº¦: é«˜ - å¯é çš„åŒ¹é…")
        elif result['best_similarity'] > 0.6:
            print("ğŸŸ  å®šä½ç²¾åº¦: ä¸­ç­‰ - å¯èƒ½çš„åŒ¹é…")
        else:
            print("ğŸ”´ å®šä½ç²¾åº¦: ä½ - ä¸ç¡®å®šçš„åŒ¹é…")
        
        return result
        
    except Exception as e:
        print(f"âŒ å®šä½å¤±è´¥: {e}")
        return None

def demo_batch_localization():
    """æ‰¹é‡å®šä½æ¼”ç¤º"""
    print("\nğŸ¯ æ‰¹é‡ä½ç½®å®šä½æ¼”ç¤º")
    print("=" * 50)
    
    model_path = "outputs/models/best_sc_ring_cnn_20250802_165529.pth"
    map_database_path = "data/raw/ply_files"
    
    if not Path(model_path).exists() or not Path(map_database_path).exists():
        print("âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡æ‰¹é‡æ¼”ç¤º")
        return
    
    try:
        # åˆå§‹åŒ–å®šä½å™¨
        localizer = PositionLocalizer(model_path, map_database_path, device='cpu')
        
        # è·å–æµ‹è¯•æ–‡ä»¶
        ply_files = list(Path(map_database_path).glob("*.ply"))
        test_files = ply_files[::50]  # æ¯50ä¸ªæ–‡ä»¶å–ä¸€ä¸ªè¿›è¡Œæµ‹è¯•
        
        print(f"ğŸ“Š æµ‹è¯• {len(test_files)} ä¸ªæ–‡ä»¶çš„å®šä½ç²¾åº¦")
        
        correct_predictions = 0
        total_time = 0
        
        for i, test_file in enumerate(test_files):
            start_time = time.time()
            result = localizer.localize_from_ply(str(test_file), top_k=1)
            end_time = time.time()
            
            processing_time = end_time - start_time
            total_time += processing_time
            
            # æ£€æŸ¥æ˜¯å¦æ­£ç¡®é¢„æµ‹ï¼ˆæ–‡ä»¶ååŒ¹é…ï¼‰
            predicted_file = result['best_map_file']
            actual_file = test_file.name
            
            is_correct = predicted_file == actual_file
            if is_correct:
                correct_predictions += 1
            
            print(f"  æµ‹è¯• {i+1:2d}/{len(test_files)}: "
                  f"å®é™…={actual_file[:15]:<15} "
                  f"é¢„æµ‹={predicted_file[:15]:<15} "
                  f"ç›¸ä¼¼åº¦={result['best_similarity']:.3f} "
                  f"{'âœ…' if is_correct else 'âŒ'}")
        
        # ç»Ÿè®¡ç»“æœ
        accuracy = correct_predictions / len(test_files)
        avg_time = total_time / len(test_files)
        
        print(f"\nğŸ“ˆ æ‰¹é‡æµ‹è¯•ç»“æœ:")
        print(f"  å‡†ç¡®ç‡: {accuracy:.2%} ({correct_predictions}/{len(test_files)})")
        print(f"  å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.3f}ç§’")
        print(f"  æ€»å¤„ç†æ—¶é—´: {total_time:.2f}ç§’")
        
    except Exception as e:
        print(f"âŒ æ‰¹é‡æµ‹è¯•å¤±è´¥: {e}")

def demo_usage_guide():
    """ä½¿ç”¨æŒ‡å—"""
    print("\nğŸ“– ä½ç½®å®šä½ç³»ç»Ÿä½¿ç”¨æŒ‡å—")
    print("=" * 50)
    
    print("1. ğŸ—ï¸  å‡†å¤‡å·¥ä½œ:")
    print("   - è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶ (.pth)")
    print("   - åœ°å›¾æ•°æ®åº“ç›®å½• (åŒ…å«æ‰€æœ‰å‚è€ƒä½ç½®çš„PLYæ–‡ä»¶)")
    print("   - æŸ¥è¯¢PLYæ–‡ä»¶ (å½“å‰ä½ç½®çš„ç‚¹äº‘)")
    
    print("\n2. ğŸ”§ å‘½ä»¤è¡Œä½¿ç”¨:")
    print("   python localize_position.py \\")
    print("     --model outputs/models/best_sc_ring_cnn_xxx.pth \\")
    print("     --map_database data/raw/ply_files \\")
    print("     --query /path/to/current_position.ply \\")
    print("     --top_k 5")
    
    print("\n3. ğŸ¤– ROSèŠ‚ç‚¹ä½¿ç”¨:")
    print("   rosrun your_package ros_localization_node.py \\")
    print("     _model_path:=outputs/models/best_sc_ring_cnn_xxx.pth \\")
    print("     _map_database_path:=data/raw/ply_files \\")
    print("     _pointcloud_topic:=/velodyne_points")
    
    print("\n4. ğŸ Python APIä½¿ç”¨:")
    print("   from localize_position import PositionLocalizer")
    print("   localizer = PositionLocalizer(model_path, map_db_path)")
    print("   result = localizer.localize_from_ply(query_ply)")
    print("   position_index = result['best_position_index']")
    
    print("\n5. ğŸ“Š è¾“å‡ºè§£é‡Š:")
    print("   - position_index: åœ¨åœ°å›¾ä¸­çš„ä½ç½®ç´¢å¼• (0, 1, 2, ...)")
    print("   - similarity: ç›¸ä¼¼åº¦åˆ†æ•° (0-1, è¶Šé«˜è¶Šç›¸ä¼¼)")
    print("   - confidence: ç½®ä¿¡åº¦ç­‰çº§ (high/medium/low)")
    print("   - map_file: å¯¹åº”çš„åœ°å›¾æ–‡ä»¶å")
    
    print("\n6. ğŸ¯ åç»­è·¯å¾„è§„åˆ’:")
    print("   - è·å¾—ä½ç½®ç´¢å¼•åï¼Œå¯ä»¥:")
    print("     * æŸ¥è¯¢é¢„å®šä¹‰çš„è·¯å¾„è§„åˆ’è¡¨")
    print("     * è®¡ç®—åˆ°ç›®æ ‡ä½ç½®çš„è·¯å¾„")
    print("     * æ‰§è¡Œå¯¼èˆªæ§åˆ¶å‘½ä»¤")

def main():
    parser = argparse.ArgumentParser(description='ä½ç½®å®šä½æ¼”ç¤º')
    parser.add_argument('--demo', type=str, choices=['single', 'batch', 'guide', 'all'], 
                       default='all', help='æ¼”ç¤ºç±»å‹')
    
    args = parser.parse_args()
    
    print("ğŸ¯ ä½ç½®å®šä½ç³»ç»Ÿæ¼”ç¤º")
    print("åŸºäºæ·±åº¦å­¦ä¹ çš„ç‚¹äº‘ä½ç½®å®šä½")
    print("=" * 60)
    
    if args.demo in ['single', 'all']:
        demo_single_localization()
    
    if args.demo in ['batch', 'all']:
        demo_batch_localization()
    
    if args.demo in ['guide', 'all']:
        demo_usage_guide()
    
    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
    print("ç°åœ¨æ‚¨å¯ä»¥ä½¿ç”¨è¿™ä¸ªç³»ç»Ÿè¿›è¡Œå®æ—¶ä½ç½®å®šä½äº†ã€‚")

if __name__ == "__main__":
    main()
