#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è°ƒè¯•æ•°æ®æ³„éœ²é—®é¢˜
"""

import numpy as np
import torch
from models.cnn_2d_models import Simple2DCNN
from utils.scan_context import ScanContext
from utils.ply_reader import PLYReader
import glob
from pathlib import Path

def test_data_leakage():
    """æµ‹è¯•æ˜¯å¦å­˜åœ¨æ•°æ®æ³„éœ²"""
    
    print("ğŸ” æ•°æ®æ³„éœ²è°ƒè¯•æµ‹è¯•")
    print("="*50)
    
    # 1. æ£€æŸ¥æ ‡ç­¾ç”Ÿæˆé€»è¾‘
    print("1. æ ‡ç­¾ç”Ÿæˆé€»è¾‘æ£€æŸ¥:")
    total_files = 1769
    num_classes = 20
    
    print("è®­ç»ƒæ ‡ç­¾ç”Ÿæˆ:")
    for i in [0, 88, 177, 354, 531, 708, 885, 1062, 1239, 1416, 1593, 1769-1]:
        progress = int((i / total_files) * num_classes)
        progress = min(progress, num_classes - 1)
        print(f"  æ–‡ä»¶ç´¢å¼• {i:4d} -> æ ‡ç­¾ {progress:2d}")
    
    print("\næµ‹è¯•æ ‡ç­¾ç”Ÿæˆ:")
    for total_messages in [1, 89, 178, 355, 532, 709, 886, 1063, 1240, 1417, 1594, 1769]:
        expected_segment = int((total_messages - 1) / (1769 / 20))
        expected_segment = min(expected_segment, 19)
        print(f"  æ¶ˆæ¯ç´¢å¼• {total_messages:4d} -> æœŸæœ›æ®µ {expected_segment:2d}")
    
    # 2. æµ‹è¯•éšæœºè¾“å…¥
    print("\n2. éšæœºè¾“å…¥æµ‹è¯•:")
    
    # åŠ è½½æ¨¡å‹
    model_path = "models/saved/simple2dcnn_trajectory_avg99.5.pth"
    if not Path(model_path).exists():
        print("âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    model = Simple2DCNN(num_classes=20)
    checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    print("æµ‹è¯•éšæœºè¾“å…¥çš„é¢„æµ‹ç»“æœ:")
    with torch.no_grad():
        for i in range(10):
            # ç”Ÿæˆéšæœºè¾“å…¥
            random_input = torch.randn(1, 1, 20, 60)
            output = model(random_input)
            probabilities = torch.softmax(output, dim=1)
            confidence, predicted = torch.max(probabilities, 1)
            
            print(f"  éšæœºè¾“å…¥ {i+1}: é¢„æµ‹æ®µ {predicted.item():2d}, ç½®ä¿¡åº¦ {confidence.item():.4f}")
    
    # 3. æµ‹è¯•å›ºå®šæ¨¡å¼è¾“å…¥
    print("\n3. å›ºå®šæ¨¡å¼è¾“å…¥æµ‹è¯•:")
    
    patterns = {
        "å…¨é›¶": torch.zeros(1, 1, 20, 60),
        "å…¨ä¸€": torch.ones(1, 1, 20, 60),
        "å¯¹è§’çº¿": torch.zeros(1, 1, 20, 60),
        "ä¸­å¿ƒç‚¹": torch.zeros(1, 1, 20, 60),
        "è¾¹ç¼˜": torch.zeros(1, 1, 20, 60)
    }
    
    # åˆ›å»ºç‰¹å®šæ¨¡å¼
    patterns["å¯¹è§’çº¿"][0, 0, range(20), range(0, 60, 3)] = 1.0
    patterns["ä¸­å¿ƒç‚¹"][0, 0, 10, 30] = 1.0
    patterns["è¾¹ç¼˜"][0, 0, [0, 19], :] = 1.0
    patterns["è¾¹ç¼˜"][0, 0, :, [0, 59]] = 1.0
    
    with torch.no_grad():
        for name, pattern in patterns.items():
            output = model(pattern)
            probabilities = torch.softmax(output, dim=1)
            confidence, predicted = torch.max(probabilities, 1)
            
            print(f"  {name:6s}: é¢„æµ‹æ®µ {predicted.item():2d}, ç½®ä¿¡åº¦ {confidence.item():.4f}")
    
    # 4. æ£€æŸ¥ScanContextæ˜¯å¦åŒ…å«æ—¶åºä¿¡æ¯
    print("\n4. ScanContextæ—¶åºä¿¡æ¯æ£€æŸ¥:")
    
    data_dir = "/mysda/shared_dir/2025.7.3/2025-07-03-16-28-57.ply"
    ply_files = sorted(glob.glob(f"{data_dir}/*.ply"))
    
    if len(ply_files) > 0:
        sc_generator = ScanContext()
        
        # æ£€æŸ¥å‰å‡ ä¸ªå’Œåå‡ ä¸ªæ–‡ä»¶çš„ScanContext
        test_indices = [0, 1, 2, len(ply_files)//2-1, len(ply_files)//2, len(ply_files)//2+1, -3, -2, -1]
        
        print("æ–‡ä»¶ScanContextç»Ÿè®¡:")
        for idx in test_indices:
            if 0 <= idx < len(ply_files) or idx < 0:
                try:
                    ply_file = ply_files[idx]
                    points = PLYReader.read_ply_file(ply_file)
                    if points is not None:
                        points = points[:, :3]
                        sc = sc_generator.generate_scan_context(points)
                        
                        if sc is not None:
                            # è®¡ç®—ä¸€äº›ç»Ÿè®¡é‡
                            mean_val = np.mean(sc)
                            std_val = np.std(sc)
                            max_val = np.max(sc)
                            nonzero_count = np.count_nonzero(sc)
                            
                            print(f"  æ–‡ä»¶ {idx:4d}: å‡å€¼={mean_val:.4f}, æ ‡å‡†å·®={std_val:.4f}, æœ€å¤§å€¼={max_val:.4f}, éé›¶={nonzero_count}")
                        
                except Exception as e:
                    print(f"  æ–‡ä»¶ {idx:4d}: å¤„ç†å¤±è´¥ - {e}")
    
    print("\nğŸ” è°ƒè¯•å®Œæˆ")

def test_shuffled_prediction():
    """æµ‹è¯•æ‰“ä¹±é¡ºåºåçš„é¢„æµ‹"""
    print("\n5. æ‰“ä¹±é¡ºåºæµ‹è¯•:")
    
    # åŠ è½½æ¨¡å‹
    model_path = "models/saved/simple2dcnn_trajectory_avg99.5.pth"
    if not Path(model_path).exists():
        print("âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    model = Simple2DCNN(num_classes=20)
    checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    # ç”Ÿæˆä¸€äº›æµ‹è¯•æ•°æ®
    data_dir = "/mysda/shared_dir/2025.7.3/2025-07-03-16-28-57.ply"
    ply_files = sorted(glob.glob(f"{data_dir}/*.ply"))
    
    if len(ply_files) < 100:
        print("âŒ æ–‡ä»¶æ•°é‡ä¸è¶³")
        return
    
    sc_generator = ScanContext()
    
    # é€‰æ‹©ä¸€äº›æ–‡ä»¶è¿›è¡Œæµ‹è¯•
    test_files = ply_files[::100]  # æ¯100ä¸ªæ–‡ä»¶é€‰ä¸€ä¸ª
    
    print("åŸå§‹é¡ºåºé¢„æµ‹:")
    original_predictions = []
    
    for i, ply_file in enumerate(test_files):
        try:
            points = PLYReader.read_ply_file(ply_file)
            if points is not None:
                points = points[:, :3]
                sc = sc_generator.generate_scan_context(points)
                
                if sc is not None:
                    sc_tensor = torch.FloatTensor(sc).unsqueeze(0).unsqueeze(0)
                    
                    with torch.no_grad():
                        output = model(sc_tensor)
                        probabilities = torch.softmax(output, dim=1)
                        confidence, predicted = torch.max(probabilities, 1)
                        
                        original_predictions.append(predicted.item())
                        print(f"  æ–‡ä»¶ {i*100:4d}: é¢„æµ‹æ®µ {predicted.item():2d}, ç½®ä¿¡åº¦ {confidence.item():.4f}")
        except Exception as e:
            print(f"  æ–‡ä»¶ {i*100:4d}: å¤„ç†å¤±è´¥ - {e}")
    
    print(f"\nåŸå§‹é¡ºåºé¢„æµ‹ç»“æœ: {original_predictions}")
    
    # æ‰“ä¹±é¡ºåºæµ‹è¯•
    print("\næ‰“ä¹±é¡ºåºé¢„æµ‹:")
    import random
    shuffled_files = test_files.copy()
    random.shuffle(shuffled_files)
    
    shuffled_predictions = []
    
    for i, ply_file in enumerate(shuffled_files):
        try:
            points = PLYReader.read_ply_file(ply_file)
            if points is not None:
                points = points[:, :3]
                sc = sc_generator.generate_scan_context(points)
                
                if sc is not None:
                    sc_tensor = torch.FloatTensor(sc).unsqueeze(0).unsqueeze(0)
                    
                    with torch.no_grad():
                        output = model(sc_tensor)
                        probabilities = torch.softmax(output, dim=1)
                        confidence, predicted = torch.max(probabilities, 1)
                        
                        shuffled_predictions.append(predicted.item())
                        print(f"  æ‰“ä¹± {i:4d}: é¢„æµ‹æ®µ {predicted.item():2d}, ç½®ä¿¡åº¦ {confidence.item():.4f}")
        except Exception as e:
            print(f"  æ‰“ä¹± {i:4d}: å¤„ç†å¤±è´¥ - {e}")
    
    print(f"\næ‰“ä¹±é¡ºåºé¢„æµ‹ç»“æœ: {shuffled_predictions}")
    
    # æ¯”è¾ƒç»“æœ
    if len(original_predictions) == len(shuffled_predictions):
        correlation = np.corrcoef(original_predictions, shuffled_predictions)[0, 1]
        print(f"\né¢„æµ‹ç»“æœç›¸å…³æ€§: {correlation:.4f}")
        
        if correlation > 0.8:
            print("âš ï¸  é«˜ç›¸å…³æ€§è¡¨æ˜æ¨¡å‹å¯èƒ½å­¦åˆ°äº†ä¸é¡ºåºæ— å…³çš„çœŸå®ç‰¹å¾")
        else:
            print("ğŸš¨ ä½ç›¸å…³æ€§è¡¨æ˜æ¨¡å‹ä¸¥é‡ä¾èµ–æ–‡ä»¶é¡ºåºï¼")

if __name__ == '__main__':
    test_data_leakage()
    test_shuffled_prediction()
